\section{Datenaugmentierung}
In Kapitel \ref{chap:3-datenaugmentation} ist das Vorgehen für die Datenaugmentierung beschrieben. Wie bereits gezeigt, nutzt beispielsweise die \mintinline{python}{fit}-Methode die Datenaugmentierung, um dem Generator $G$ die Größe und Perspektive des Straßenschilds vorzugeben. Hier soll auf die konkrete Implementierung dessen eingegangen werden. Zur Augmentierung müssen die Piktogramme der Straßenschilder zufällig rotiert und skaliert werden. Hierzu dient die Bibliothek Tensorflow Graphics.

Die Augmentierung ist in der Datei \mintinline{python}{utils/preprocess_image.py} implementiert. Die Funktion, die hierbei aus der CycleGAN Klasse aufgerufen wird, ist \mintinline{python}{randomly_transform_image_batch}. Das Listing \ref{lst:pictogram-augmentation} im Anhang zeigt die vollständige Implementierung. Die Funktion erhält einen vierdimensionalen Tensor \mintinline{python}{img_tensor_batch} als Eingang. Dieser Tensor beinhaltet den Batch an Bildern, der transformiert werden soll. Zunächst skaliert die Funktion zufällig den Inhalt dieser Bilder. Anschließend führt sie darauf eine zufällige dreidimensionale Rotation aus und gibt die transformierten Bilder zurück. Was sie ebenfalls zurückgibt, sind die Listen \mintinline{python}{content_sizes} und \mintinline{python}{rotation_matrices}. Die Anzahl an Elementen der Listen entspricht der Größe des übergebenen Batches, also der Anzahl an transformierten Bildern. Hierdurch kann die aufrufende Funktion für jedes Bild identifizieren, welche Zufallswerte für die Transformation generiert wurden. Dies kann genutzt werden, um die Transformation zu replizieren. Genutzt wird das in Kapitel \ref{chap:5}, um Bilder von als ungültig markierten Schildern zu erzeugen.

\subsection{Skalierung}
Die Skalierung des Bildinhalts besteht aus mehreren Schritten. Zunächst generiert die Funktion \mintinline{python}{randomly_transform_image_batch} mittels Numpy eine Liste an zufälligen \mintinline{python}{content_sizes}. Danach skaliert die Funktion die Piktogramme der Straßenschilder auf die in \mintinline{python}{content_sizes} gespeicherten Pixelgrößen mittels der Hilfsfunktion \mintinline{python}{resize_content_of_img}. Das ist in Listing \ref{lst:content-scaling} gezeigt.

\begin{code}
   \begin{minted}{python}
content_sizes_tmp = content_sizes[:]
transformed_imgs = tf.map_fn(
   lambda img: resize_content_of_img(
      img, target_size, content_sizes_tmp.pop(0)), 
   img_tensor_batch)
\end{minted}
   \captionof{listing}{\lstinline[language=python]|utils.preprocess_image.py| - Skalieren der Bild-Tensoren}
   \label{lst:content-scaling}
\end{code}

Als ersten Schritt dupliziert die Funktion die Liste \mintinline{python}{content_sizes} in einer Variable namens \mintinline{python}{content_sizes_tmp}. Anschließend skaliert die Funktion die Bilder. Dazu nutzt sie die von TensorFlow bereitgestellte Funktion \mintinline{python}{tf.map_fn}. Diese Funktion erhält als Parameter einen Tensor der Stufe $n$ und eine Funktion. Sie führt die Funktion auf jedem Element der Stufe $n-1$ des Tensors aus. Beispielsweise auf jedem Bild eines Batches von Bildern. In diesem Fall übergeben wir einen Tensor der Stufe vier und der Form \emph{(Batch Größe, Breite, Höhe, Anzahl Farbkanäle)} an die Funktion \mintinline{python}{tf.map_fn}. Die Funktion erstellt daraus eine Menge an Tensoren der Stufe drei, wobei jeder dieser Tensoren ein Bild mit der Form \emph{(Breite, Höhe, Anzahl Farbkanäle)} ist.
Auf jedem Bild führt die Funktion \mintinline{python}{tf.map_fn} anschließend die Funktion \mintinline{python}{resize_content_of_img} aus. Letztere Funktion erhält ein Bild und die Zielgröße, auf die der Inhalt des Bilds skaliert werden soll. Anschließend fügt die Funktion \mintinline{python}{tf.map_fn} die Bilder wieder zu einem einzelnen Tensor der stufe vier zusammen und gibt ihn zurück. \cite{tf-map-fn}

Es wäre ebenso möglich, über die einzelnen Bild-Tensoren des Batches mittels einer \mintinline{python}|for|-Schleife zu iterieren. Die Dokumentation von \mintinline{python}{tf.map_fn} gibt jedoch explizit an, dass sie eine parallele Ausführung ermöglicht. Das ist hier der ausschlaggebende Vorteil gegenüber einer \mintinline{python}|for|-Schleife. Es ist jedoch dennoch weniger performant als eine Funktion zu verwenden, die eine einzelne Operation vektorisiert auf dem gesamten Tensor ausführt. Warum die Funtionen dennoch mit \mintinline{python}{tf.map_fn} arbeitet, statt alle Bilder des Batchs gleichzeitig zu transformieren, soll der folgende Abschnitt klären. \cite{tf-map-fn}

Die Funktion \mintinline{python}{resize_content_of_img} verwendet zwei Funktionen aus dem TensorFlow Framework: Die Funktion \mintinline{python}{tf.image.resize} um das Bild zu skalieren und die Funktion \mintinline{python}{tf.image.resize_with_crop_or_pad} um das Bild zurück auf die ursprüngliche Größe zu bringen. Wird das Piktogramm verkleinert, dann fügt letztere Fuktion einen weißen Rand um das Piktogramm hinzu. Wird es hingegen vergrößert, schneidet die Funktion die Pixel ab, die über die Zielgröße hinausgehen. Obwohl es möglich wäre, den vierdimensionalen Tensor an beide TensorFlow Funktionen zu übergeben, um alle Bilder gleichzeitig zu skalieren, erhält \mintinline{python}{resize_content_of_img} lediglich dreidimensionale Tensoren, sprich einzelne Bilder, als Parameter. Das hängt damit zusammen, dass die Piktogramme in einem Batch unterschiedliche Skalierungen besitzen sollen. Die TensorFlow Funktionen sind jedoch nur dazu in der Lage, eine bestimmte Skalierung auf allen Bilder des Batches auszuführen.

Die Liste \mintinline{python}{content_sizes_tmp} fungiert für die Funktion \mintinline{python}{tf.map_fn} als Warteschlange \emph{engl.: Queue}. Bei jedem Durchlauf der Lambda-Funktion wird das erste Element der Liste gelesen und anschließend entfernt. Dazu dient die Listenfunktion \mintinline{python}{pop}.

\subsection{Rotation}
Der zweite Schritt der Augmentation ist, dass das Modell die Piktogramme rotiert. Es existieren Rotationsmatrizen, die Rotationen mittels eulerscher Winkel beschreiben. Die Drehungen um die x-, y- und z-Achse besitzen jeweils eigene Rotationsmatrizen $R_x$, $R_y$ und $R_z$. Der Aufbau dieser Matrizen ist der Literatur entnommen \cite{math-primer}. Um daraus eine einzelne Rotationsmatrix $R$ zu erhalten, werden die Rotationsmatrizen miteinander multipliziert. Dazu dient die Funktion \mintinline{python}{create_rotation_matrix}. Sie erhält die drei Winkel $\alpha_x$, $\alpha_y$ und $\alpha_z$ als Parameter und gibt eine einzelne Rotationsmatrix $R$ zurück.

Bevor die Funktion \mintinline{python}{randomly_transform_image_batch} die Funktion \mintinline{python}{create_rotation_matrix} aufruft, muss sie ausgehend davon zunächst zufällige Winkel $(\alpha_x, \alpha_y, \alpha_z)$ erzeugen. An dieser Stelle entstammen die zufälligen Winkel jedoch nicht einer Gleichverteilung, sondern einer gaußschen Normalverteilung. Das hängt damit zusammen, dass die Piktogramme in den meisten fällen nur leicht rotiert sein sollen. Nur ein vergleichsweise geringer Prozentsatz der Piktgoramme soll stark Augmentiert sein. Dies soll in etwa nachbilden, aus welchen Perspektiven die Straßenschilder im Trainingsdatensatz aufgenommen sind. Listing \ref{lst:alpha-z-value} zeigt die zufällige Generierung der Rotationswinkel $\alpha_z$:

\begin{code}
   \begin{minted}{python}
alpha_z_values = np.random.normal(loc=0.0, scale=3.5, 
                                 size=batch_size)
\end{minted}
   \captionof{listing}{\lstinline[language=python]|utils.preprocess_image.py| - Zufällige Generierung der Rotationswinkel $\alpha_z$}
   \label{lst:alpha-z-value}
   \end{code}

Der Parameter \mintinline{python}{loc} gibt den Erwartungswert der Winkel an, während \mintinline{python}{scale} die Standardabweichung setzt. Durch das Angeben der \mintinline{python}{batch_size} wird deutlich, dass die Numpy Funktin hier nicht nur einen Winkel erzeugt wird, sondern ein \emph{Numpy Array} das für jedes Piktogramm einen zufälligen Winkel enthält. Die Implementierung ist somit hier vektorisiert. Im Mittel liegen die Winkel der Rotation bei 0,0\textdegree. Der Wert für die Standardabweichung ist empirisch bestimmt, da die Werte für die Winkel nicht den tatsächlichen Winkeln in Grad entsprechen. Die Funktion \mintinline{python}{randomly_transform_image_batch} erzeugt die Winkel $\alpha_y$ und $\alpha_x$ analog hierzu, mit dem Unterschied, dass sie dort andere Standardabweichungen (\mintinline{python}{scale}) als Parameter setzt. Dass eine gaußsche Normalverteilung verwendet wird, bedeutet, dass die meisten Piktogramme zu einer Aufnahme aus der Frontalperspektive führen. Der Großteil der Rotationswinkel ist demnach vergleichsweise gering. Einige wenige Schilder hingegen sind stärker rotiert. Würde die Funktion eine Gleichverteilung zur Erzeugung der Winkel verwenden, wäre der Anteil an starken Rotationen in etwa gleich zu dem Anteil an geringen Rotationen.

Die eigentliche Rotation setzt die TensorFlow Graphics Funktion \mintinline{python}{perspective_transform} um. Sie erhält einen Tensor der Stufe vier an Bildern und einen Tensor der Stufe vier an Rotationsmatrizen. Das bedeutet, dass der gesamte Batch an Bildern samt seiner Rotationsmatrizen übergeben wird. Somit erfolgt die Augmentation der Bilder hier vektorisiert und damit parallel. Die Codezeile \mintinline{python}{transformed_imgs = 1 - transformed_imgs} kehrt vor der Rotation zunächst die Farbwerte des Bilds um. Das ist nötig, da der Hintergrund, den die genannte TensorFlow Funktion erzeugt, schwarz ist. Kehrt man zunächst die Farbwerte um, führt die Rotation aus und setzt die Farbwerte auf ihren ursprünglichen Wert zurück, so wird der schwarze Hintergrund durch einen weißen ersetzt.